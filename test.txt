// Function to measure memory bandwidth
void measure_memory_bandwidth(float *d_A, float *d_B, float *d_C, int M, int N, int K, float avg_time_ms) {
    // Calculate memory traffic
    // Each GEMM reads M*K elements from A, K*N from B, and reads+writes M*N from C
    double bytes_read = (M * K + K * N + M * N) * sizeof(float);
    double bytes_written = M * N * sizeof(float);
    double total_bytes = bytes_read + bytes_written;
    
    // Calculate bandwidth in GB/s
    double bandwidth = total_bytes / (avg_time_ms * 1e-3) / 1e9;
    
    printf("Memory Bandwidth: %.2f GB/s\n", bandwidth);
    printf("Memory Read: %.2f GB\n", bytes_read / 1e9);
    printf("Memory Written: %.2f GB\n", bytes_written / 1e9);
}

// Function to benchmark with varying matrix sizes
void benchmark_varying_sizes() {
    int sizes[] = {1024, 2048, 4096, 8192};
    int num_sizes = sizeof(sizes) / sizeof(sizes[0]);
    
    printf("\nBenchmarking with varying matrix sizes:\n");
    printf("----------------------------------------\n");
    printf("Size\tTime (ms)\tGFLOPS\tBandwidth (GB/s)\n");
    
    for (int i = 0; i < num_sizes; i++) {
        int M = sizes[i];
        int N = sizes[i];
        int K = sizes[i];
        
        // Run benchmark with this size (code omitted for brevity)
        // ...
        
        // Print results
        // printf("%d\t%.3f\t\t%.2f\t%.2f\n", M, avg_time_ms, gflops, bandwidth);
    }
}

// Function to benchmark with different grid/block sizes
void benchmark_grid_block_configs(int M, int N, int K) {
    int block_sizes[] = {8, 16, 32};
    int num_configs = sizeof(block_sizes) / sizeof(block_sizes[0]);
    
    printf("\nBenchmarking with different grid/block configurations:\n");
    printf("-----------------------------------------------------\n");
    printf("Block Size\tTime (ms)\tGFLOPS\n");
    
    for (int i = 0; i < num_configs; i++) {
        int block_size = block_sizes[i];
        dim3 blockDim(block_size, block_size, 1);
        dim3 gridDim(CEIL_DIV(M, block_size), CEIL_DIV(N, block_size), 1);
        
        // Run benchmark with this configuration (code omitted for brevity)
        // ...
        
        // Print results
        // printf("%d x %d\t%.3f\t\t%.2f\n", block_size, block_size, avg_time_ms, gflops);
    }
}

// Function to measure peak achievable performance
void measure_peak_performance() {
    // Get device properties
    int device_id;
    cudaGetDevice(&device_id);
    
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, device_id);
    
    // Calculate theoretical peak performance
    // For FP32 operations
    int cuda_cores = prop.multiProcessorCount * 64; // Assuming SM has 64 cores (varies by architecture)
    float clock_rate_ghz = prop.clockRate / 1e6; // Convert from kHz to GHz
    
    // Each CUDA core can do 2 FP32 operations per cycle (FMA = multiply + add)
    float peak_gflops = 2.0f * cuda_cores * clock_rate_ghz;
    
    printf("\nDevice: %s\n", prop.name);
    printf("CUDA Cores: %d\n", cuda_cores);
    printf("Clock Rate: %.2f GHz\n", clock_rate_ghz);
    printf("Theoretical Peak Performance: %.2f GFLOPS\n", peak_gflops);
}

// Function to measure power consumption (requires NVML)
void measure_power_consumption() {
    nvmlReturn_t result;
    nvmlDevice_t device;
    unsigned int power;
    
    // Initialize NVML
    result = nvmlInit();
    if (result != NVML_SUCCESS) {
        printf("Failed to initialize NVML: %s\n", nvmlErrorString(result));
        return;
    }
    
    // Get the device handle
    result = nvmlDeviceGetHandleByIndex(0, &device);
    if (result != NVML_SUCCESS) {
        printf("Failed to get device handle: %s\n", nvmlErrorString(result));
        nvmlShutdown();
        return;
    }
    
    // Get power usage
    result = nvmlDeviceGetPowerUsage(device, &power);
    if (result == NVML_SUCCESS) {
        printf("Power Usage: %.2f W\n", power / 1000.0);
    } else {
        printf("Failed to get power usage: %s\n", nvmlErrorString(result));
    }
    
    // Shutdown NVML
    nvmlShutdown();